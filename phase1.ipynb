{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "phase1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyBvpTEbpVd7"
      },
      "source": [
        "import pandas as pd\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import advanced_processor_chain_factory\n",
        "import simple_processor_chain_factory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "nNRN4SV-pVd9"
      },
      "source": [
        "gdd.download_file_from_google_drive(file_id='15JJ6ZysFM57tlUjXo2nHVhkGwePbVMVV',dest_path='./dataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "rbwKnQ_7pVd-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b8013ac1-b885-4a32-b7ea-bce748fe8786"
      },
      "source": [
        "dataset = pd.read_csv('./dataset.csv')\n",
        "dataset['sentiment'] = dataset['sentiment'].replace(['negative', 'positive'] , [0, 1])\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Oh my god, it just doesn't get any worse than ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>If you're a layman interested in quantum theor...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It's amazing that this no talent actor Chapa g...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This must be one of the most overrated Spanish...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Some critics have compared Chop Shop with the ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment  sentiment\n",
              "0  Oh my god, it just doesn't get any worse than ...          0\n",
              "1  If you're a layman interested in quantum theor...          0\n",
              "2  It's amazing that this no talent actor Chapa g...          0\n",
              "3  This must be one of the most overrated Spanish...          0\n",
              "4  Some critics have compared Chop Shop with the ...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "zvihraVfpVd_"
      },
      "source": [
        "def analysis(labels, predictions):\n",
        "    print(\"Report: Classification\\n\", classification_report(labels, predictions, target_names=[\"positive\", \"negative\"]))\n",
        "    print(\"Matrix: Confusion\\n\", confusion_matrix(labels, predictions))\n",
        "    print(\"Accuracy:\\n\", accuracy_score(labels, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgNOED_YpVd_"
      },
      "source": [
        "def evaluate_models_with_data(models, X_train, X_test, Y_train, Y_test):\n",
        "    for name, model in models.items():\n",
        "        print(f'------Evaluating {name}------')\n",
        "        model.fit(X_train, Y_train)\n",
        "        pred = model.predict(X_test)\n",
        "        analysis(Y_test, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "XrZuySyrpVd_"
      },
      "source": [
        "models = {'logistic regression' : LogisticRegression(class_weight = 'balanced'),\n",
        "          'svm' : svm.SVC(),\n",
        "          'knn' : KNeighborsClassifier(n_neighbors=8)\n",
        "         }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "NQHG9rwqpVeA"
      },
      "source": [
        "def prepare_data(vectorizer, processor_chain = None, debug = False, debug_data_size = 4000):\n",
        "    X , Y = dataset['comment'], dataset['sentiment']\n",
        "    if debug:\n",
        "        X , Y = X[:debug_data_size], Y[:debug_data_size]\n",
        "    if processor_chain:\n",
        "        X = X.apply(processor_chain.process)\n",
        "    X = vectorizer(X)\n",
        "    return train_test_split(X,Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlLV5NUR7iIW"
      },
      "source": [
        "# Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFSF0zcBs1Za"
      },
      "source": [
        "def count_vectorizer(X):\n",
        "  vectorizer = CountVectorizer(max_features = 2000)\n",
        "  return vectorizer.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPeK64al7mZK"
      },
      "source": [
        "## Without Pre-Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6sjNr9zlpVeA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "527b9a8c-4163-4ce5-fd47-009dcd4895f2"
      },
      "source": [
        "evaluate_models_with_data(models, *prepare_data(count_vectorizer, debug = True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------Evaluating logistic regression------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Report: Classification\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.86      0.77      0.81       499\n",
            "    negative       0.79      0.88      0.83       501\n",
            "\n",
            "    accuracy                           0.82      1000\n",
            "   macro avg       0.83      0.82      0.82      1000\n",
            "weighted avg       0.83      0.82      0.82      1000\n",
            "\n",
            "Matrix: Confusion\n",
            " [[384 115]\n",
            " [ 61 440]]\n",
            "Accuracy:\n",
            " 0.824\n",
            "------Evaluating svm------\n",
            "Report: Classification\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.83      0.70      0.76       499\n",
            "    negative       0.74      0.85      0.79       501\n",
            "\n",
            "    accuracy                           0.78      1000\n",
            "   macro avg       0.78      0.77      0.77      1000\n",
            "weighted avg       0.78      0.78      0.77      1000\n",
            "\n",
            "Matrix: Confusion\n",
            " [[347 152]\n",
            " [ 73 428]]\n",
            "Accuracy:\n",
            " 0.775\n",
            "------Evaluating knn------\n",
            "Report: Classification\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.62      0.61      0.61       499\n",
            "    negative       0.62      0.63      0.62       501\n",
            "\n",
            "    accuracy                           0.62      1000\n",
            "   macro avg       0.62      0.62      0.62      1000\n",
            "weighted avg       0.62      0.62      0.62      1000\n",
            "\n",
            "Matrix: Confusion\n",
            " [[304 195]\n",
            " [187 314]]\n",
            "Accuracy:\n",
            " 0.618\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GU6tcyNX7sCw"
      },
      "source": [
        "## Simple Pre-Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3Pga30JpVeB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb8d049c-3280-438d-c91d-823a2e747b2e"
      },
      "source": [
        "evaluate_models_with_data(models, *prepare_data(count_vectorizer,processor_chain=simple_processor_chain_factory.create(), debug=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------Evaluating logistic regression------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Report: Classification\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.85      0.83      0.84       514\n",
            "    negative       0.83      0.85      0.84       486\n",
            "\n",
            "    accuracy                           0.84      1000\n",
            "   macro avg       0.84      0.84      0.84      1000\n",
            "weighted avg       0.84      0.84      0.84      1000\n",
            "\n",
            "Matrix: Confusion\n",
            " [[427  87]\n",
            " [ 74 412]]\n",
            "Accuracy:\n",
            " 0.839\n",
            "------Evaluating svm------\n",
            "Report: Classification\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.81      0.75      0.78       514\n",
            "    negative       0.76      0.82      0.79       486\n",
            "\n",
            "    accuracy                           0.78      1000\n",
            "   macro avg       0.79      0.78      0.78      1000\n",
            "weighted avg       0.79      0.78      0.78      1000\n",
            "\n",
            "Matrix: Confusion\n",
            " [[386 128]\n",
            " [ 88 398]]\n",
            "Accuracy:\n",
            " 0.784\n",
            "------Evaluating knn------\n",
            "Report: Classification\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.62      0.60      0.61       514\n",
            "    negative       0.59      0.60      0.60       486\n",
            "\n",
            "    accuracy                           0.60      1000\n",
            "   macro avg       0.60      0.60      0.60      1000\n",
            "weighted avg       0.60      0.60      0.60      1000\n",
            "\n",
            "Matrix: Confusion\n",
            " [[310 204]\n",
            " [193 293]]\n",
            "Accuracy:\n",
            " 0.603\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYR-1Was7xkp"
      },
      "source": [
        "## Pre-Process with Lemmitization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9JGevP0pVeB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "188fd510-3b01-4cb5-c336-cbdfc71056ee"
      },
      "source": [
        "evaluate_models_with_data(models, *prepare_data(count_vectorizer,processor_chain=advanced_processor_chain_factory.create('lem'), debug=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------Evaluating logistic regression------\n",
            "Report: Classification\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.83      0.82      0.83       490\n",
            "    negative       0.83      0.84      0.83       510\n",
            "\n",
            "    accuracy                           0.83      1000\n",
            "   macro avg       0.83      0.83      0.83      1000\n",
            "weighted avg       0.83      0.83      0.83      1000\n",
            "\n",
            "Matrix: Confusion\n",
            " [[403  87]\n",
            " [ 83 427]]\n",
            "Accuracy:\n",
            " 0.83\n",
            "------Evaluating svm------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Report: Classification\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.86      0.78      0.81       490\n",
            "    negative       0.80      0.87      0.84       510\n",
            "\n",
            "    accuracy                           0.83      1000\n",
            "   macro avg       0.83      0.83      0.83      1000\n",
            "weighted avg       0.83      0.83      0.83      1000\n",
            "\n",
            "Matrix: Confusion\n",
            " [[381 109]\n",
            " [ 64 446]]\n",
            "Accuracy:\n",
            " 0.827\n",
            "------Evaluating knn------\n",
            "Report: Classification\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.62      0.75      0.68       490\n",
            "    negative       0.70      0.56      0.63       510\n",
            "\n",
            "    accuracy                           0.66      1000\n",
            "   macro avg       0.66      0.66      0.65      1000\n",
            "weighted avg       0.67      0.66      0.65      1000\n",
            "\n",
            "Matrix: Confusion\n",
            " [[369 121]\n",
            " [222 288]]\n",
            "Accuracy:\n",
            " 0.657\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nN5nTx7T74Ox"
      },
      "source": [
        "## Pre-Process with Stemmimg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7QhNjp0pVeB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5057e1c8-3d61-4e6e-d4f2-934ee6f93084"
      },
      "source": [
        "evaluate_models_with_data(models, *prepare_data(count_vectorizer,processor_chain=advanced_processor_chain_factory.create('stem'), debug=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------Evaluating logistic regression------\n",
            "Report: Classification\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.84      0.83      0.84       509\n",
            "    negative       0.83      0.84      0.83       491\n",
            "\n",
            "    accuracy                           0.83      1000\n",
            "   macro avg       0.83      0.84      0.83      1000\n",
            "weighted avg       0.84      0.83      0.84      1000\n",
            "\n",
            "Matrix: Confusion\n",
            " [[424  85]\n",
            " [ 80 411]]\n",
            "Accuracy:\n",
            " 0.835\n",
            "------Evaluating svm------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Report: Classification\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.85      0.80      0.82       509\n",
            "    negative       0.80      0.85      0.83       491\n",
            "\n",
            "    accuracy                           0.82      1000\n",
            "   macro avg       0.83      0.83      0.82      1000\n",
            "weighted avg       0.83      0.82      0.82      1000\n",
            "\n",
            "Matrix: Confusion\n",
            " [[407 102]\n",
            " [ 73 418]]\n",
            "Accuracy:\n",
            " 0.825\n",
            "------Evaluating knn------\n",
            "Report: Classification\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.62      0.73      0.67       509\n",
            "    negative       0.66      0.54      0.59       491\n",
            "\n",
            "    accuracy                           0.64      1000\n",
            "   macro avg       0.64      0.63      0.63      1000\n",
            "weighted avg       0.64      0.64      0.63      1000\n",
            "\n",
            "Matrix: Confusion\n",
            " [[371 138]\n",
            " [227 264]]\n",
            "Accuracy:\n",
            " 0.635\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29jDFYxW8IEQ"
      },
      "source": [
        "## Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEVITkobpVeC"
      },
      "source": [
        "import itertools\n",
        "\n",
        "class Word2VecDataProvider:\n",
        "  \n",
        "  def __init__(self, processor_chain, debug = False, debug_data_size = 20000):\n",
        "    X , Y = dataset['comment'], dataset['sentiment']\n",
        "    if debug:\n",
        "      X , Y = X[:debug_data_size] , Y[:debug_data_size]\n",
        "    sentences = X.apply(nltk.sent_tokenize)\n",
        "    sentences = sentences.apply(lambda com: \n",
        "                                [nltk.word_tokenize(processor_chain.process(s)) \n",
        "                                for s in com])\n",
        "    self.data =  list(itertools.chain.from_iterable(sentences.to_list()))    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cz444lDsENGK"
      },
      "source": [
        "from gensim.models import word2vec\n",
        "import numpy as np\n",
        "\n",
        "class Word2Vec: \n",
        "  \n",
        "  def __init__(self, num_features=250, min_count=40,workers=4,\n",
        "               window=10,sample=0.001):\n",
        "    \n",
        "    self.num_features=num_features\n",
        "    self.min_count=min_count\n",
        "    self.workers=workers\n",
        "    self.window=window\n",
        "    self.sample=sample\n",
        "    \n",
        "  \n",
        "  def fit(self,data):\n",
        "    self.model = word2vec.Word2Vec(data, workers = self.workers, \n",
        "                            size = self.num_features, min_count = self.min_count,\n",
        "                            window = self.window, sample = self.sample)\n",
        "    self.model.init_sims(replace = True)\n",
        "\n",
        "\n",
        "  def predict(self,comment):\n",
        "    result = np.zeros((self.num_features,), dtype = \"float32\")\n",
        "    word_index = set(self.model.wv.index2word)\n",
        "    nword = 0\n",
        "    for word in comment:\n",
        "        if word in word_index:\n",
        "            nword += 1\n",
        "            result = np.add(result, self.model[word])\n",
        "    return np.divide(result, nword)    \n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJIoQhfwUpwD",
        "outputId": "753a46a2-624d-4757-a04e-f01351888731"
      },
      "source": [
        "processor_chain = simple_processor_chain_factory.create()\n",
        "word2vec_data = Word2VecDataProvider(processor_chain=processor_chain, debug=True).data\n",
        "w2v_model = Word2Vec()\n",
        "w2v_model.fit(word2vec_data)\n",
        "\n",
        "def w2v_vectorizer(X):\n",
        "  return X.apply(lambda comment: pd.Series(w2v_model.predict(\n",
        "      nltk.word_tokenize(processor_chain.process(comment)))))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/bs4/__init__.py:273: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
            "  ' Beautiful Soup.' % markup)\n",
            "/usr/local/lib/python3.7/dist-packages/bs4/__init__.py:336: UserWarning: \"http://www.happierabroad.com\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4hXhrjvwZkA",
        "outputId": "5d6a9200-df85-4f4b-99cb-cf42fdaa9168"
      },
      "source": [
        "evaluate_models_with_data(models, *prepare_data(w2v_vectorizer,processor_chain=processor_chain, debug=True))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "------Evaluating logistic regression------\n",
            "Report: Classification\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.77      0.77      0.77       497\n",
            "    negative       0.77      0.77      0.77       503\n",
            "\n",
            "    accuracy                           0.77      1000\n",
            "   macro avg       0.77      0.77      0.77      1000\n",
            "weighted avg       0.77      0.77      0.77      1000\n",
            "\n",
            "Matrix: Confusion\n",
            " [[381 116]\n",
            " [114 389]]\n",
            "Accuracy:\n",
            " 0.77\n",
            "------Evaluating svm------\n",
            "Report: Classification\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.85      0.79      0.82       497\n",
            "    negative       0.81      0.86      0.83       503\n",
            "\n",
            "    accuracy                           0.83      1000\n",
            "   macro avg       0.83      0.83      0.83      1000\n",
            "weighted avg       0.83      0.83      0.83      1000\n",
            "\n",
            "Matrix: Confusion\n",
            " [[394 103]\n",
            " [ 71 432]]\n",
            "Accuracy:\n",
            " 0.826\n",
            "------Evaluating knn------\n",
            "Report: Classification\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.72      0.82      0.76       497\n",
            "    negative       0.79      0.68      0.73       503\n",
            "\n",
            "    accuracy                           0.75      1000\n",
            "   macro avg       0.75      0.75      0.75      1000\n",
            "weighted avg       0.75      0.75      0.75      1000\n",
            "\n",
            "Matrix: Confusion\n",
            " [[406  91]\n",
            " [160 343]]\n",
            "Accuracy:\n",
            " 0.749\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}