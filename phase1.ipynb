{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "phase1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mryf323/ml_final_project/blob/main/phase1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyBvpTEbpVd7"
      },
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import advanced_processor_chain_factory\n",
        "import simple_processor_chain_factory"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "nNRN4SV-pVd9"
      },
      "source": [
        "gdd.download_file_from_google_drive(file_id='15JJ6ZysFM57tlUjXo2nHVhkGwePbVMVV',dest_path='./dataset.csv')"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "rbwKnQ_7pVd-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e3ca791d-6f82-49ff-a25c-e3afa07284b1"
      },
      "source": [
        "dataset = pd.read_csv('./dataset.csv')\n",
        "dataset['sentiment'] = dataset['sentiment'].replace(['negative', 'positive'] , [0, 1])\n",
        "dataset.head()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Oh my god, it just doesn't get any worse than ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>If you're a layman interested in quantum theor...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It's amazing that this no talent actor Chapa g...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This must be one of the most overrated Spanish...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Some critics have compared Chop Shop with the ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment  sentiment\n",
              "0  Oh my god, it just doesn't get any worse than ...          0\n",
              "1  If you're a layman interested in quantum theor...          0\n",
              "2  It's amazing that this no talent actor Chapa g...          0\n",
              "3  This must be one of the most overrated Spanish...          0\n",
              "4  Some critics have compared Chop Shop with the ...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "zvihraVfpVd_"
      },
      "source": [
        "def analysis(labels, predictions):\n",
        "    #print(\"Report: Classification\\n\", classification_report(labels, predictions, target_names=[\"positive\", \"negative\"]))\n",
        "    #print(\"Matrix: Confusion\\n\", confusion_matrix(labels, predictions))\n",
        "    print(\"Accuracy:\\n\", accuracy_score(labels, predictions))"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgNOED_YpVd_"
      },
      "source": [
        "def evaluate_models_with_data(models, X_train, X_test, Y_train, Y_test):\n",
        "    for name, model in models.items():\n",
        "        print(f'------Evaluating {name}------')\n",
        "        model.fit(X_train, Y_train)\n",
        "        pred = model.predict(X_test)\n",
        "        analysis(Y_test, pred)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "XrZuySyrpVd_"
      },
      "source": [
        "models = {'logistic regression' : LogisticRegression(class_weight = 'balanced'),\n",
        "          'svm' : svm.SVC(),\n",
        "          'knn' : KNeighborsClassifier(n_neighbors=8)\n",
        "         }"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "NQHG9rwqpVeA"
      },
      "source": [
        "def prepare_data(processor_chain = None, debug = False, debug_data_size = 4000):\n",
        "    X , Y = dataset['comment'], dataset['sentiment']\n",
        "    if debug:\n",
        "        X , Y = X[:debug_data_size], Y[:debug_data_size]\n",
        "    if processor_chain:\n",
        "        X = X.apply(processor_chain.process)\n",
        "    vectorizer = CountVectorizer(max_features = 2000)\n",
        "    X = vectorizer.fit_transform(X)\n",
        "    return train_test_split(X,Y)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6sjNr9zlpVeA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f63f4e81-cade-44c0-984c-969da6e537b8"
      },
      "source": [
        "evaluate_models_with_data(models, *prepare_data(debug = True))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------Evaluating logistic regression------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:\n",
            " 0.837\n",
            "------Evaluating svm------\n",
            "Accuracy:\n",
            " 0.778\n",
            "------Evaluating knn------\n",
            "Accuracy:\n",
            " 0.628\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3Pga30JpVeB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cc65cf7-a9a9-4b5a-86a6-dcc59e3c2b80"
      },
      "source": [
        "evaluate_models_with_data(models, *prepare_data(processor_chain=simple_processor_chain_factory.create(), debug=True))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------Evaluating logistic regression------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:\n",
            " 0.837\n",
            "------Evaluating svm------\n",
            "Accuracy:\n",
            " 0.804\n",
            "------Evaluating knn------\n",
            "Accuracy:\n",
            " 0.614\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9JGevP0pVeB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5c1c8eb-f699-4781-9177-12becc171662"
      },
      "source": [
        "evaluate_models_with_data(models, *prepare_data(processor_chain=advanced_processor_chain_factory.create('lem'), debug=True))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------Evaluating logistic regression------\n",
            "Accuracy:\n",
            " 0.822\n",
            "------Evaluating svm------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:\n",
            " 0.827\n",
            "------Evaluating knn------\n",
            "Accuracy:\n",
            " 0.643\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7QhNjp0pVeB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e543773-0cb0-4056-e459-fd705e5239ea"
      },
      "source": [
        "evaluate_models_with_data(models, *prepare_data(processor_chain=advanced_processor_chain_factory.create('stem'), debug=True))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------Evaluating logistic regression------\n",
            "Accuracy:\n",
            " 0.836\n",
            "------Evaluating svm------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:\n",
            " 0.814\n",
            "------Evaluating knn------\n",
            "Accuracy:\n",
            " 0.648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEVITkobpVeC"
      },
      "source": [
        "class Word2VecDataProvider:\n",
        "  \n",
        "  def __init__(self, processor_chain, debug = False, debug_data_size = 4000):\n",
        "    X , Y = dataset['comment'], dataset['sentiment']\n",
        "    if debug:\n",
        "      X , Y = X[:debug_data_size] , Y[:debug_data_size]\n",
        "    sentences = X.apply(nltk.sent_tokenize)\n",
        "    sentences = sentences.apply(lambda com: \n",
        "                                [nltk.word_tokenize(processor_chain.process(s)) \n",
        "                                for s in com])\n",
        "    self.data =  list(itertools.chain.from_iterable(sentences.to_list()))    "
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cz444lDsENGK"
      },
      "source": [
        "from gensim.models import word2vec\n",
        "\n",
        "class Word2Vec: \n",
        "  \n",
        "  def __init__(self, num_features=250, min_count=40,workers=4,\n",
        "               window=10,sample=0.001):\n",
        "    \n",
        "    self.num_features=num_features\n",
        "    self.min_count=min_count\n",
        "    self.workers=workers\n",
        "    self.window=window\n",
        "    self.sample=sample\n",
        "    \n",
        "  \n",
        "  def fit(data):\n",
        "    self.model = word2vec.Word2Vec(data, workers = self.workers, \n",
        "                            size = self.num_features, min_count = self.min_count,\n",
        "                            window = self.window, sample = self.sample)\n",
        "    self.model.init_sims(replace = True)\n",
        "\n",
        "\n",
        "  def predict(self,comment):\n",
        "    result = np.zeros((self.num_features,), dtype = \"float32\")\n",
        "    word_index = set(self.model.wv.index2word)\n",
        "    nword = 0\n",
        "    for word in comment:\n",
        "        if word in word_index:\n",
        "            nword += 1\n",
        "            result = np.add(result, self.model[word])\n",
        "    return np.divide(featureVec, nword)    \n",
        "\n",
        "  "
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJIoQhfwUpwD",
        "outputId": "81e79124-740c-4234-8203-4280d6eae090"
      },
      "source": [
        "processor_chain = simple_processor_chain_factory.create()\n",
        "word2vec_data = Word2VecDataProvider(processor_chain=processor_chain, debug=True).data\n",
        "w2v_model = Word2Vec()\n",
        "w2v_model.fit(word2vec_data)\n",
        "\n",
        "def w2v_convertor(comment):\n",
        "  return w2v_model.predict(nltk.word_tokenize(processor_chain.process(comment)))\n",
        "\n"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('awful', 0.923717737197876),\n",
              " ('terrible', 0.8872237801551819),\n",
              " ('lame', 0.8860093355178833),\n",
              " ('horrible', 0.8857911229133606),\n",
              " ('overall', 0.8806014060974121),\n",
              " ('predictable', 0.872204601764679),\n",
              " ('writing', 0.8648942708969116),\n",
              " ('average', 0.8497321605682373),\n",
              " ('scary', 0.84068363904953),\n",
              " ('totally', 0.8344157338142395)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    }
  ]
}