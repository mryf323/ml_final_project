{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "colab": {
   "name": "phase1.ipynb",
   "provenance": [],
   "collapsed_sections": []
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "uyBvpTEbpVd7"
   },
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from data import preprocess_data, vectorize_data, load_dataset\n",
    "from evaluation import analysis, evaluate_models_with_data\n",
    "from w2v_adapter import Word2VecAdapter\n",
    "\n",
    "import advanced_processor_chain_factory\n",
    "import simple_processor_chain_factory"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "rbwKnQ_7pVd-",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "outputId": "b8013ac1-b885-4a32-b7ea-bce748fe8786"
   },
   "source": [
    "dataset = load_dataset()\n",
    "DEBUG = False"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlLV5NUR7iIW"
   },
   "source": [
    "# Inspection of Pre-Processing Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models = {'logistic regression' : LogisticRegression(class_weight = 'balanced', n_jobs=-1),\n",
    "          'svm' : svm.LinearSVC(),\n",
    "          'knn' : KNeighborsClassifier(n_neighbors=8, n_jobs=-1)\n",
    "         }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPeK64al7mZK"
   },
   "source": [
    "## Without Pre-Process"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "6sjNr9zlpVeA",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "527b9a8c-4163-4ce5-fd47-009dcd4895f2"
   },
   "source": [
    "evaluate_models_with_data(models, *vectorize_data(*preprocess_data(dataset, debug=DEBUG), CountVectorizer(max_features=2000)))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GU6tcyNX7sCw"
   },
   "source": [
    "## Simple Pre-Process"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "f3Pga30JpVeB",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "bb8d049c-3280-438d-c91d-823a2e747b2e"
   },
   "source": [
    "evaluate_models_with_data(models,\n",
    "                          *vectorize_data(\n",
    "                              *preprocess_data(dataset, processor_chain=simple_processor_chain_factory.create(), debug=DEBUG),\n",
    "                              CountVectorizer(max_features=2000)))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nN5nTx7T74Ox"
   },
   "source": [
    "## Pre-Process with Stemmimg"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "m7QhNjp0pVeB",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5057e1c8-3d61-4e6e-d4f2-934ee6f93084"
   },
   "source": [
    "evaluate_models_with_data(models,\n",
    "                          *vectorize_data(\n",
    "                              *preprocess_data(dataset, processor_chain=advanced_processor_chain_factory.create('stem'),\n",
    "                                               debug=DEBUG),\n",
    "                              CountVectorizer(max_features=2000)))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-Process with Lemmitization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Dask Apply:   0%|          | 0/8 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "46b3910124aa46aa8fb5e34ee376fe1a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, Y = preprocess_data(dataset, processor_chain=advanced_processor_chain_factory.create('lem'), debug=DEBUG)\n",
    "del dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_bow, X_test_bow, Y_train_bow, Y_test_bow = vectorize_data(X, Y,CountVectorizer(max_features=2000))\n",
    "evaluate_models_with_data(models, X_train_bow, X_test_bow, Y_train_bow, Y_test_bow)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29jDFYxW8IEQ"
   },
   "source": [
    "# Compare W2V and BoW with Their Best Tuned Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5)\n",
    "general_grid_params = {'verbose' : 1, 'cv' : kfold, 'n_jobs' : -1, 'scoring' : 'f1'}\n",
    "\n",
    "logistic_grid = {\n",
    "    'penalty':['l2'],\n",
    "    'C':[1, 300, 500, 700, 900, 2000],\n",
    "    'class_weight':['balanced'],\n",
    "    'solver':['saga'],\n",
    "    'n_jobs':[-1],\n",
    "    'max_iter':[1000],\n",
    "}\n",
    "\n",
    "svc_grid = {\n",
    "    'kernel' : ['linear', 'rbf'],\n",
    "    'C':[0.1, 1, 300, 500, 700],\n",
    "}\n",
    "\n",
    "knn_grid = {\n",
    "    'n_neighbors' : [i for i in range(1,24,2)],\n",
    "    'n_jobs' : [-1]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BoW"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bow_log = LogisticRegression()\n",
    "bow_log = GridSearchCV(estimator=bow_log, param_grid=logistic_grid, **general_grid_params)\n",
    "bow_log.fit(X_train_bow, Y_train_bow)\n",
    "print(f'Best Score: {bow_log.best_score_}')\n",
    "print(f'Best Params: {bow_log.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "analysis(Y_test_bow, bow_log.predict(X_test_bow))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bow_svm = svm.SVC()\n",
    "bow_svm = GridSearchCV(estimator=bow_svm, param_grid=svc_grid, **general_grid_params)\n",
    "bow_svm.fit(X_train_bow, Y_train_bow)\n",
    "print(f'Best Score: {bow_svm.best_score_}')\n",
    "print(f'Best Params: {bow_svm.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "analysis(Y_test_bow, bow_svm.predict(X_test_bow))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bow_knn = KNeighborsClassifier()\n",
    "bow_knn = GridSearchCV(estimator=bow_knn, param_grid=knn_grid, **general_grid_params)\n",
    "bow_knn.fit(X_train_bow, Y_train_bow)\n",
    "print(f'Best Score: {bow_svm.best_score_}')\n",
    "print(f'Best Params: {bow_svm.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "analysis(Y_test_bow, bow_svm.predict(X_test_bow))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## W2V"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4hXhrjvwZkA",
    "outputId": "5d6a9200-df85-4f4b-99cb-cf42fdaa9168",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "X_train_w2v, X_test_w2v, Y_train_w2v, Y_test_w2v = train_test_split(X, Y)\n",
    "\n",
    "if os.path.isfile('w2v.kv'):\n",
    "    vectorizer = Word2VecAdapter(KeyedVectors.load('vectors.kv'))\n",
    "else:\n",
    "    vectorizer = Word2VecAdapter()\n",
    "    vectorizer.wv.save('w2v.kv')\n",
    "\n",
    "X_train_w2v = vectorizer.fit_transform(X_train_w2v)\n",
    "X_test_w2v = vectorizer.transform(X_test_w2v)\n"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "Dask Apply:   0%|          | 0/8 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b33389e50d58439a860ec51ad5fbca95"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-4-3227d0f773c0>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mX_train_w2v\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_test_w2v\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY_train_w2v\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY_test_w2v\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvectorize_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mWord2VecAdapter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/ml_final_project/data.py\u001B[0m in \u001B[0;36mvectorize_data\u001B[0;34m(X, Y, vectorizer)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mvectorize_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvectorizer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m     \u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY_test\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_test_split\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 25\u001B[0;31m     \u001B[0mX_train\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvectorizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit_transform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     26\u001B[0m     \u001B[0mX_test\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvectorizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY_test\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/ml_final_project/w2v_adapter.py\u001B[0m in \u001B[0;36mfit_transform\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m     36\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mfit_transform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwv\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 38\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     39\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mswifter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mallow_dask_on_strings\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSeries\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/ml_final_project/w2v_adapter.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m     24\u001B[0m             model = word2vec.Word2Vec(X, workers=self.workers,\n\u001B[1;32m     25\u001B[0m                                       \u001B[0mvector_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnum_features\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmin_count\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmin_count\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 26\u001B[0;31m                                       window=self.window, sample=self.sample)\n\u001B[0m\u001B[1;32m     27\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwv\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwv\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mword_index\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mindex_to_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/ml_final_project/venv/lib/python3.6/site-packages/gensim/models/word2vec.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, sentences, corpus_file, vector_size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, epochs, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, comment, max_final_vocab)\u001B[0m\n\u001B[1;32m    420\u001B[0m                 \u001B[0mcorpus_iterable\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcorpus_iterable\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcorpus_file\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcorpus_file\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtotal_examples\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcorpus_count\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    421\u001B[0m                 \u001B[0mtotal_words\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcorpus_total_words\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mepochs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstart_alpha\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0malpha\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 422\u001B[0;31m                 end_alpha=self.min_alpha, compute_loss=self.compute_loss, callbacks=callbacks)\n\u001B[0m\u001B[1;32m    423\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    424\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mtrim_rule\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/ml_final_project/venv/lib/python3.6/site-packages/gensim/models/word2vec.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001B[0m\n\u001B[1;32m   1063\u001B[0m                     \u001B[0mcorpus_iterable\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcur_epoch\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcur_epoch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtotal_examples\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtotal_examples\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1064\u001B[0m                     \u001B[0mtotal_words\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtotal_words\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mqueue_factor\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mqueue_factor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreport_delay\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mreport_delay\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1065\u001B[0;31m                     callbacks=callbacks, **kwargs)\n\u001B[0m\u001B[1;32m   1066\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1067\u001B[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch_corpusfile(\n",
      "\u001B[0;32m~/PycharmProjects/ml_final_project/venv/lib/python3.6/site-packages/gensim/models/word2vec.py\u001B[0m in \u001B[0;36m_train_epoch\u001B[0;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay, callbacks)\u001B[0m\n\u001B[1;32m   1423\u001B[0m         trained_word_count, raw_word_count, job_tally = self._log_epoch_progress(\n\u001B[1;32m   1424\u001B[0m             \u001B[0mprogress_queue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mjob_queue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcur_epoch\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcur_epoch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtotal_examples\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtotal_examples\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1425\u001B[0;31m             \u001B[0mtotal_words\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtotal_words\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreport_delay\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mreport_delay\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_corpus_file_mode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1426\u001B[0m         )\n\u001B[1;32m   1427\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/ml_final_project/venv/lib/python3.6/site-packages/gensim/models/word2vec.py\u001B[0m in \u001B[0;36m_log_epoch_progress\u001B[0;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001B[0m\n\u001B[1;32m   1276\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1277\u001B[0m         \u001B[0;32mwhile\u001B[0m \u001B[0munfinished_worker_count\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1278\u001B[0;31m             \u001B[0mreport\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mprogress_queue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# blocks if workers too slow\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1279\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mreport\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# a thread reporting that it finished\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1280\u001B[0m                 \u001B[0munfinished_worker_count\u001B[0m \u001B[0;34m-=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.6/queue.py\u001B[0m in \u001B[0;36mget\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m    162\u001B[0m             \u001B[0;32melif\u001B[0m \u001B[0mtimeout\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    163\u001B[0m                 \u001B[0;32mwhile\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_qsize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 164\u001B[0;31m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnot_empty\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    165\u001B[0m             \u001B[0;32melif\u001B[0m \u001B[0mtimeout\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    166\u001B[0m                 \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"'timeout' must be a non-negative number\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.6/threading.py\u001B[0m in \u001B[0;36mwait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    293\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m    \u001B[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    294\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mtimeout\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 295\u001B[0;31m                 \u001B[0mwaiter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0macquire\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    296\u001B[0m                 \u001B[0mgotit\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    297\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conf = {'C': 1, 'class_weight': 'balanced', 'max_iter': 1000, 'n_jobs': -1, 'penalty': 'l2', 'solver': 'saga'}\n",
    "w2v_log = LogisticRegression(**conf)\n",
    "w2v_log.fit(X_train_w2v, Y_train_w2v)\n",
    "analysis(Y_test_w2v, w2v_log.predict(X_test_w2v))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w2v_log = LogisticRegression()\n",
    "w2v_log = GridSearchCV(estimator=w2v_log, param_grid=logistic_grid, **general_grid_params)\n",
    "w2v_log.fit(X_train_w2v, Y_train_w2v)\n",
    "print(f'Best Score: {w2v_log.best_score_}')\n",
    "print(f'Best Params: {w2v_log.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "analysis(Y_test_w2v, w2v_log.predict(X_test_w2v))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w2v_svm = svm.SVC()\n",
    "w2v_svm = GridSearchCV(estimator=w2v_svm, param_grid=svc_grid, **general_grid_params)\n",
    "w2v_svm.fit(X_train_w2v, Y_train_w2v)\n",
    "print(f'Best Score: {w2v_svm.best_score_}')\n",
    "print(f'Best Params: {w2v_svm.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "analysis(Y_test_w2v, w2v_svm.predict(X_test_w2v))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w2v_knn = KNeighborsClassifier()\n",
    "w2v_knn = GridSearchCV(estimator=w2v_knn, param_grid=knn_grid, **general_grid_params)\n",
    "w2v_knn.fit(X_train_w2v, Y_train_w2v)\n",
    "print(f'Best Score: {w2v_svm.best_score_}')\n",
    "print(f'Best Params: {w2v_svm.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "analysis(Y_test_w2v, w2v_svm.predict(X_test_w2v))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparison"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "summary = {\n",
    "    'LR': {'BoW': bow_log, 'W2V': w2v_log},\n",
    "    'SVM' : {'BoW': bow_svm, 'W2V': w2v_svm},\n",
    "    'KNN': {'BoW': bow_knn, 'W2V': w2v_knn},\n",
    "  }\n",
    "\n",
    "for name, values in summary.items():\n",
    "    print(f'For classifier {name}, best BoW score is {values[\"BoW\"].best_score_}, whereas best W2V score is {values[\"W2V\"].best_score_}')\n",
    "    best_model = \"BoW\" if values[\"BoW\"].best_score_ > values[\"W2V\"].best_score_ else \"W2V\"\n",
    "    print(f'So {best_model} is better with parameters {values[best_model].best_params_}')\n",
    "    filename = name + '.pkl'\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(values[best_model], f)\n",
    "\n",
    "del summary, bow_log, w2v_log, bow_svm, w2v_svm, bow_knn, w2v_knn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MLP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mlp_grid = {\n",
    "    #\n",
    "    #(1000, 250), (500, 250, 250),(1000, 500,250)\n",
    "    'hidden_layer_sizes':[(500, 250)],\n",
    "    #, 'relu'\n",
    "    'activation':['tanh']\n",
    "}\n",
    "def eval_mlp(X_train, X_test, Y_train, Y_test):\n",
    "    best_f1 = -1\n",
    "    best_model = None\n",
    "    for sizes in mlp_grid['hidden_layer_sizes']:\n",
    "        for act in mlp_grid['activation']:\n",
    "            m = MLPClassifier(hidden_layer_sizes=sizes, activation=act, solver='sgd', alpha=1,\n",
    "                                    learning_rate='adaptive', max_iter=10)\n",
    "            m.fit(X_train, Y_train)\n",
    "            print(f'Model config: hidden_layer_sizes={sizes}, activation={act}')\n",
    "            f1 = analysis(Y_test, m.predict(X_test))\n",
    "            if f1 > best_f1:\n",
    "                best_model = m\n",
    "                best_f1 = f1\n",
    "    return best_f1, best_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## W2V"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w2v_f1, w2v_mlp = eval_mlp(X_train_w2v, X_test_w2v, Y_train_w2v, Y_test_w2v)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del X_train_w2v, X_test_w2v, Y_train_w2v, Y_test_w2v"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BoW"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bow_f1, bow_mlp = eval_mlp(X_train_bow, X_test_bow, Y_train_bow, Y_test_bow)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del X_train_bow, X_test_bow, Y_train_bow, Y_test_bow"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TD-IDF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_idf, X_test_idf, Y_train_idf, Y_test_idf = vectorize_data(X, Y, TfidfVectorizer(max_features=2000))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf_idf_f1, tf_idf_mlp = eval_mlp(X_train_idf, X_test_idf, Y_train_idf, Y_test_idf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del X_train_idf, X_test_idf, Y_train_idf, Y_test_idf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparison"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Best scores:')\n",
    "print(f'W2V: {w2v_f1} with params: {w2v_mlp.get_params()}')\n",
    "print(f'BoW: {bow_f1} with params: {bow_mlp.get_params()}')\n",
    "print(f'Tf-Idf: {tf_idf_f1} with params: {tf_idf_mlp.get_params()}')\n",
    "\n",
    "idx = np.argmax([w2v_f1, bow_f1, tf_idf_f1])\n",
    "best_mlp = [w2v_mlp, bow_mlp, tf_idf_mlp][idx]\n",
    "\n",
    "with open('best.pkl', 'wb') as f:\n",
    "    pickle.dump(best_mlp, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}