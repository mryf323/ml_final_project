{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import advanced_processor_chain_factory\n",
    "import simple_processor_chain_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gdd.download_file_from_google_drive(file_id='15JJ6ZysFM57tlUjXo2nHVhkGwePbVMVV',dest_path='./dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oh my god, it just doesn't get any worse than ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you're a layman interested in quantum theor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's amazing that this no talent actor Chapa g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This must be one of the most overrated Spanish...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Some critics have compared Chop Shop with the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  sentiment\n",
       "0  Oh my god, it just doesn't get any worse than ...          0\n",
       "1  If you're a layman interested in quantum theor...          0\n",
       "2  It's amazing that this no talent actor Chapa g...          0\n",
       "3  This must be one of the most overrated Spanish...          0\n",
       "4  Some critics have compared Chop Shop with the ...          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('./dataset.csv')\n",
    "dataset['sentiment'] = dataset['sentiment'].replace(['negative', 'positive'] , [0, 1])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def analysis(labels, predictions):\n",
    "    print(\"Report: Classification\\n\", classification_report(labels, predictions, target_names=[\"positive\", \"negative\"]))\n",
    "    print(\"Matrix: Confusion\\n\", confusion_matrix(labels, predictions))\n",
    "    print(\"Accuracy:\\n\", accuracy_score(labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models_with_data(models, X_train, X_test, Y_train, Y_test):\n",
    "    for name, model in models.items():\n",
    "        print(f'------Evaluating {name}------')\n",
    "        model.fit(X_train, Y_train)\n",
    "        pred = model.predict(X_test)\n",
    "        analysis(Y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "models = {'logistic regression' : LogisticRegression(class_weight = 'balanced'),\n",
    "          'svm' : svm.SVC(),\n",
    "          'knn' : KNeighborsClassifier(n_neighbors=8)\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_data(processor_chain = None, debug = False, debug_data_size = 4000):\n",
    "    X , Y = dataset['comment'], dataset['sentiment']\n",
    "    if debug:\n",
    "        X , Y = X[:debug_data_size], Y[:debug_data_size]\n",
    "    if processor_chain:\n",
    "        X = X.apply(processor_chain.process)\n",
    "    vectorizer = CountVectorizer(max_features = 2000)\n",
    "    X = vectorizer.fit_transform(X)\n",
    "    return train_test_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Evaluating logistic regression------\n",
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.82      0.81      0.81       508\n",
      "    negative       0.81      0.81      0.81       492\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.81      0.81      0.81      1000\n",
      "weighted avg       0.81      0.81      0.81      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[413  95]\n",
      " [ 93 399]]\n",
      "Accuracy:\n",
      " 0.812\n",
      "------Evaluating svm------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mryf/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.78      0.72      0.75       508\n",
      "    negative       0.73      0.80      0.76       492\n",
      "\n",
      "    accuracy                           0.76      1000\n",
      "   macro avg       0.76      0.76      0.76      1000\n",
      "weighted avg       0.76      0.76      0.76      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[364 144]\n",
      " [100 392]]\n",
      "Accuracy:\n",
      " 0.756\n",
      "------Evaluating knn------\n",
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.62      0.66      0.64       508\n",
      "    negative       0.62      0.59      0.61       492\n",
      "\n",
      "    accuracy                           0.62      1000\n",
      "   macro avg       0.62      0.62      0.62      1000\n",
      "weighted avg       0.62      0.62      0.62      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[333 175]\n",
      " [202 290]]\n",
      "Accuracy:\n",
      " 0.623\n"
     ]
    }
   ],
   "source": [
    "evaluate_models_with_data(models, *prepare_data(debug = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Evaluating logistic regression------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mryf/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.84      0.85      0.84       510\n",
      "    negative       0.84      0.83      0.83       490\n",
      "\n",
      "    accuracy                           0.84      1000\n",
      "   macro avg       0.84      0.84      0.84      1000\n",
      "weighted avg       0.84      0.84      0.84      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[431  79]\n",
      " [ 85 405]]\n",
      "Accuracy:\n",
      " 0.836\n",
      "------Evaluating svm------\n",
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.79      0.75      0.77       510\n",
      "    negative       0.75      0.79      0.77       490\n",
      "\n",
      "    accuracy                           0.77      1000\n",
      "   macro avg       0.77      0.77      0.77      1000\n",
      "weighted avg       0.77      0.77      0.77      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[380 130]\n",
      " [101 389]]\n",
      "Accuracy:\n",
      " 0.769\n",
      "------Evaluating knn------\n",
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.62      0.65      0.64       510\n",
      "    negative       0.62      0.58      0.60       490\n",
      "\n",
      "    accuracy                           0.62      1000\n",
      "   macro avg       0.62      0.62      0.62      1000\n",
      "weighted avg       0.62      0.62      0.62      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[333 177]\n",
      " [204 286]]\n",
      "Accuracy:\n",
      " 0.619\n"
     ]
    }
   ],
   "source": [
    "evaluate_models_with_data(models, *prepare_data(processor_chain=simple_processor_chain_factory.create(), debug=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Evaluating logistic regression------\n",
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.83      0.82      0.83       489\n",
      "    negative       0.83      0.84      0.84       511\n",
      "\n",
      "    accuracy                           0.83      1000\n",
      "   macro avg       0.83      0.83      0.83      1000\n",
      "weighted avg       0.83      0.83      0.83      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[403  86]\n",
      " [ 83 428]]\n",
      "Accuracy:\n",
      " 0.831\n",
      "------Evaluating svm------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mryf/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.86      0.79      0.82       489\n",
      "    negative       0.81      0.87      0.84       511\n",
      "\n",
      "    accuracy                           0.83      1000\n",
      "   macro avg       0.84      0.83      0.83      1000\n",
      "weighted avg       0.83      0.83      0.83      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[386 103]\n",
      " [ 64 447]]\n",
      "Accuracy:\n",
      " 0.833\n",
      "------Evaluating knn------\n",
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.59      0.79      0.68       489\n",
      "    negative       0.71      0.48      0.57       511\n",
      "\n",
      "    accuracy                           0.63      1000\n",
      "   macro avg       0.65      0.63      0.62      1000\n",
      "weighted avg       0.65      0.63      0.62      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[387 102]\n",
      " [267 244]]\n",
      "Accuracy:\n",
      " 0.631\n"
     ]
    }
   ],
   "source": [
    "evaluate_models_with_data(models, *prepare_data(processor_chain=advanced_processor_chain_factory.create('lem'), debug=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Evaluating logistic regression------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mryf/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.85      0.81      0.83       521\n",
      "    negative       0.81      0.85      0.83       479\n",
      "\n",
      "    accuracy                           0.83      1000\n",
      "   macro avg       0.83      0.83      0.83      1000\n",
      "weighted avg       0.83      0.83      0.83      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[424  97]\n",
      " [ 74 405]]\n",
      "Accuracy:\n",
      " 0.829\n",
      "------Evaluating svm------\n",
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.87      0.78      0.82       521\n",
      "    negative       0.78      0.87      0.83       479\n",
      "\n",
      "    accuracy                           0.82      1000\n",
      "   macro avg       0.83      0.83      0.82      1000\n",
      "weighted avg       0.83      0.82      0.82      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[406 115]\n",
      " [ 61 418]]\n",
      "Accuracy:\n",
      " 0.824\n",
      "------Evaluating knn------\n",
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.66      0.77      0.71       521\n",
      "    negative       0.69      0.58      0.63       479\n",
      "\n",
      "    accuracy                           0.68      1000\n",
      "   macro avg       0.68      0.67      0.67      1000\n",
      "weighted avg       0.68      0.68      0.67      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[399 122]\n",
      " [202 277]]\n",
      "Accuracy:\n",
      " 0.676\n"
     ]
    }
   ],
   "source": [
    "evaluate_models_with_data(models, *prepare_data(processor_chain=advanced_processor_chain_factory.create('stem'), debug=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
