{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "colab": {
   "name": "phase1.ipynb",
   "provenance": [],
   "collapsed_sections": []
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "uyBvpTEbpVd7"
   },
   "source": [
    "import pickle\n",
    "import swifter\n",
    "import pandas as pd\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "import advanced_processor_chain_factory\n",
    "import simple_processor_chain_factory"
   ],
   "execution_count": 93,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "gdd.download_file_from_google_drive(file_id='15JJ6ZysFM57tlUjXo2nHVhkGwePbVMVV',dest_path='./dataset.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "rbwKnQ_7pVd-",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "outputId": "b8013ac1-b885-4a32-b7ea-bce748fe8786"
   },
   "source": [
    "dataset = pd.read_csv('./dataset.csv')\n",
    "dataset['sentiment'] = dataset['sentiment'].replace(['negative', 'positive'] , [0, 1])\n",
    "dataset.head()\n",
    "DEBUG = True"
   ],
   "execution_count": 96,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "def analysis(labels, predictions):\n",
    "    print(\"Report: Classification\\n\", classification_report(labels, predictions, target_names=[\"positive\", \"negative\"]))\n",
    "    print(\"Matrix: Confusion\\n\", confusion_matrix(labels, predictions))\n",
    "    print(\"Accuracy:\\n\", accuracy_score(labels, predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "def evaluate_models_with_data(models, X_train, X_test, Y_train, Y_test):\n",
    "    for name, model in models.items():\n",
    "        print(f'------Evaluating {name}------')\n",
    "        model.fit(X_train, Y_train)\n",
    "        pred = model.predict(X_test)\n",
    "        analysis(Y_test, pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "def preprocess_data(processor_chain = None, debug = False, debug_data_size = 4000):\n",
    "    X , Y = dataset['comment'], dataset['sentiment']\n",
    "    if debug:\n",
    "        X , Y = X[:debug_data_size], Y[:debug_data_size]\n",
    "    if processor_chain:\n",
    "        X = X.swifter.apply(processor_chain.process)\n",
    "    return X, Y\n",
    "\n",
    "def vectorize_data(X, Y, vectorizer):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y)\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    return X_train, X_test, Y_train, Y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlLV5NUR7iIW"
   },
   "source": [
    "# Inspection of Pre-Processing Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "models = {'logistic regression' : LogisticRegression(class_weight = 'balanced', n_jobs=-1),\n",
    "          'svm' : svm.LinearSVC(),\n",
    "          'knn' : KNeighborsClassifier(n_neighbors=8, n_jobs=-1)\n",
    "         }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPeK64al7mZK"
   },
   "source": [
    "## Without Pre-Process"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "6sjNr9zlpVeA",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "527b9a8c-4163-4ce5-fd47-009dcd4895f2"
   },
   "source": [
    "evaluate_models_with_data(models, *vectorize_data(*preprocess_data(debug=DEBUG), CountVectorizer(max_features=2000)))"
   ],
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Evaluating logistic regression------\n",
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.84      0.83      0.84       500\n",
      "    negative       0.83      0.85      0.84       500\n",
      "\n",
      "    accuracy                           0.84      1000\n",
      "   macro avg       0.84      0.84      0.84      1000\n",
      "weighted avg       0.84      0.84      0.84      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[416  84]\n",
      " [ 77 423]]\n",
      "Accuracy:\n",
      " 0.839\n",
      "------Evaluating svm------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mryf/PycharmProjects/ml_final_project/venv/lib/python3.6/site-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.82      0.81      0.81       500\n",
      "    negative       0.81      0.82      0.81       500\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.81      0.81      0.81      1000\n",
      "weighted avg       0.81      0.81      0.81      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[406  94]\n",
      " [ 92 408]]\n",
      "Accuracy:\n",
      " 0.814\n",
      "------Evaluating knn------\n",
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.58      0.68      0.62       500\n",
      "    negative       0.61      0.50      0.55       500\n",
      "\n",
      "    accuracy                           0.59      1000\n",
      "   macro avg       0.59      0.59      0.59      1000\n",
      "weighted avg       0.59      0.59      0.59      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[340 160]\n",
      " [250 250]]\n",
      "Accuracy:\n",
      " 0.59\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GU6tcyNX7sCw"
   },
   "source": [
    "## Simple Pre-Process"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "f3Pga30JpVeB",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "bb8d049c-3280-438d-c91d-823a2e747b2e"
   },
   "source": [
    "evaluate_models_with_data(models,\n",
    "                          *vectorize_data(\n",
    "                              *preprocess_data(processor_chain=simple_processor_chain_factory.create(), debug=DEBUG),\n",
    "                              CountVectorizer(max_features=2000)))"
   ],
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "Pandas Apply:   0%|          | 0/4000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d031207fafc43018d6b745ec468f498"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Evaluating logistic regression------\n",
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.86      0.82      0.84       501\n",
      "    negative       0.83      0.87      0.85       499\n",
      "\n",
      "    accuracy                           0.84      1000\n",
      "   macro avg       0.85      0.85      0.84      1000\n",
      "weighted avg       0.85      0.84      0.84      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[411  90]\n",
      " [ 65 434]]\n",
      "Accuracy:\n",
      " 0.845\n",
      "------Evaluating svm------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mryf/PycharmProjects/ml_final_project/venv/lib/python3.6/site-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.83      0.79      0.81       501\n",
      "    negative       0.80      0.84      0.82       499\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.81      0.81      0.81      1000\n",
      "weighted avg       0.81      0.81      0.81      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[396 105]\n",
      " [ 81 418]]\n",
      "Accuracy:\n",
      " 0.814\n",
      "------Evaluating knn------\n",
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.60      0.65      0.63       501\n",
      "    negative       0.62      0.57      0.59       499\n",
      "\n",
      "    accuracy                           0.61      1000\n",
      "   macro avg       0.61      0.61      0.61      1000\n",
      "weighted avg       0.61      0.61      0.61      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[327 174]\n",
      " [217 282]]\n",
      "Accuracy:\n",
      " 0.609\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nN5nTx7T74Ox"
   },
   "source": [
    "## Pre-Process with Stemmimg"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "m7QhNjp0pVeB",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5057e1c8-3d61-4e6e-d4f2-934ee6f93084"
   },
   "source": [
    "evaluate_models_with_data(models,\n",
    "                          *vectorize_data(\n",
    "                              *preprocess_data(processor_chain=advanced_processor_chain_factory.create('stem'),\n",
    "                                               debug=DEBUG),\n",
    "                              CountVectorizer(max_features=2000)))"
   ],
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "Pandas Apply:   0%|          | 0/4000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c40a0a5895d04e7da17d6d90bf84df49"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Evaluating logistic regression------\n",
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.83      0.83      0.83       499\n",
      "    negative       0.83      0.83      0.83       501\n",
      "\n",
      "    accuracy                           0.83      1000\n",
      "   macro avg       0.83      0.83      0.83      1000\n",
      "weighted avg       0.83      0.83      0.83      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[412  87]\n",
      " [ 85 416]]\n",
      "Accuracy:\n",
      " 0.828\n",
      "------Evaluating svm------\n",
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.81      0.81      0.81       499\n",
      "    negative       0.81      0.81      0.81       501\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.81      0.81      0.81      1000\n",
      "weighted avg       0.81      0.81      0.81      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[404  95]\n",
      " [ 96 405]]\n",
      "Accuracy:\n",
      " 0.809\n",
      "------Evaluating knn------\n",
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.65      0.72      0.68       499\n",
      "    negative       0.69      0.61      0.64       501\n",
      "\n",
      "    accuracy                           0.67      1000\n",
      "   macro avg       0.67      0.67      0.66      1000\n",
      "weighted avg       0.67      0.67      0.66      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[361 138]\n",
      " [197 304]]\n",
      "Accuracy:\n",
      " 0.665\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-Process with Lemmitization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "Pandas Apply:   0%|          | 0/4000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1f4a54ebbc7f401d9bab47961f2e1367"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Evaluating logistic regression------\n",
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.83      0.83      0.83       506\n",
      "    negative       0.82      0.83      0.83       494\n",
      "\n",
      "    accuracy                           0.83      1000\n",
      "   macro avg       0.83      0.83      0.83      1000\n",
      "weighted avg       0.83      0.83      0.83      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[418  88]\n",
      " [ 83 411]]\n",
      "Accuracy:\n",
      " 0.829\n",
      "------Evaluating svm------\n",
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.81      0.80      0.81       506\n",
      "    negative       0.80      0.81      0.80       494\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.81      0.81      0.81      1000\n",
      "weighted avg       0.81      0.81      0.81      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[407  99]\n",
      " [ 95 399]]\n",
      "Accuracy:\n",
      " 0.806\n",
      "------Evaluating knn------\n",
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.62      0.79      0.70       506\n",
      "    negative       0.70      0.51      0.59       494\n",
      "\n",
      "    accuracy                           0.65      1000\n",
      "   macro avg       0.66      0.65      0.64      1000\n",
      "weighted avg       0.66      0.65      0.64      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[400 106]\n",
      " [243 251]]\n",
      "Accuracy:\n",
      " 0.651\n"
     ]
    }
   ],
   "source": [
    "X, Y = preprocess_data(processor_chain=advanced_processor_chain_factory.create('lem'), debug=DEBUG)\n",
    "del dataset\n",
    "X_train_bow, X_test_bow, Y_train_bow, Y_test_bow = vectorize_data(X, Y,CountVectorizer(max_features=2000))\n",
    "evaluate_models_with_data(models, X_train_bow, X_test_bow, Y_train_bow, Y_test_bow)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "del models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29jDFYxW8IEQ"
   },
   "source": [
    "# Compare W2V and BoW with Their Best Tuned Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5)\n",
    "general_grid_params = {'verbose' : 1, 'cv' : kfold, 'n_jobs' : -1, 'scoring' : 'f1'}\n",
    "\n",
    "logistic_grid = {\n",
    "    'penalty':['l2'],\n",
    "    'C':[1, 300, 500, 700, 900],\n",
    "    'class_weight':['balanced'],\n",
    "    'solver':['saga'],\n",
    "    'n_jobs':[-1],\n",
    "    'max_iter':[1000],\n",
    "}\n",
    "\n",
    "svc_grid = {\n",
    "    'kernel' : ['linear', 'rbf'],\n",
    "    'C':[0.1, 1, 300, 500, 700],\n",
    "}\n",
    "\n",
    "knn_grid = {\n",
    "    'n_neighbors' : [i for i in range(1,24,2)],\n",
    "    'n_jobs' : [-1]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BoW"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "Best Score: 0.8128492870528445\n",
      "Best Params: {'C': 1, 'class_weight': 'balanced', 'max_iter': 1000, 'n_jobs': -1, 'penalty': 'l2', 'solver': 'saga'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mryf/PycharmProjects/ml_final_project/venv/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "bow_log = LogisticRegression()\n",
    "bow_log = GridSearchCV(estimator=bow_log, param_grid=logistic_grid, **general_grid_params)\n",
    "bow_log.fit(X_train_bow, Y_train_bow)\n",
    "print(f'Best Score: {bow_log.best_score_}')\n",
    "print(f'Best Params: {bow_log.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.84      0.83      0.83       506\n",
      "    negative       0.82      0.84      0.83       494\n",
      "\n",
      "    accuracy                           0.83      1000\n",
      "   macro avg       0.83      0.83      0.83      1000\n",
      "weighted avg       0.83      0.83      0.83      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[418  88]\n",
      " [ 80 414]]\n",
      "Accuracy:\n",
      " 0.832\n"
     ]
    }
   ],
   "source": [
    "analysis(Y_test_bow, bow_log.predict(X_test_bow))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "Best Score: 0.8137394686192903\n",
      "Best Params: {'C': 1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "bow_svm = svm.SVC()\n",
    "bow_svm = GridSearchCV(estimator=bow_svm, param_grid=svc_grid, **general_grid_params)\n",
    "bow_svm.fit(X_train_bow, Y_train_bow)\n",
    "print(f'Best Score: {bow_svm.best_score_}')\n",
    "print(f'Best Params: {bow_svm.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.84      0.78      0.81       506\n",
      "    negative       0.79      0.85      0.82       494\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.82      0.82      0.81      1000\n",
      "weighted avg       0.82      0.81      0.81      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[394 112]\n",
      " [ 73 421]]\n",
      "Accuracy:\n",
      " 0.815\n"
     ]
    }
   ],
   "source": [
    "analysis(Y_test_bow, bow_svm.predict(X_test_bow))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n",
      "Best Score: 0.8137394686192903\n",
      "Best Params: {'C': 1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "bow_knn = KNeighborsClassifier()\n",
    "bow_knn = GridSearchCV(estimator=bow_knn, param_grid=knn_grid, **general_grid_params)\n",
    "bow_knn.fit(X_train_bow, Y_train_bow)\n",
    "print(f'Best Score: {bow_svm.best_score_}')\n",
    "print(f'Best Params: {bow_svm.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.84      0.78      0.81       506\n",
      "    negative       0.79      0.85      0.82       494\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.82      0.82      0.81      1000\n",
      "weighted avg       0.82      0.81      0.81      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[394 112]\n",
      " [ 73 421]]\n",
      "Accuracy:\n",
      " 0.815\n"
     ]
    }
   ],
   "source": [
    "analysis(Y_test_bow, bow_svm.predict(X_test_bow))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## W2V"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Cz444lDsENGK"
   },
   "source": [
    "from gensim.models import word2vec\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "class Word2VecAdapter:\n",
    "  def __init__(self, pre_trained_model=None, num_features=250, min_count=40,workers=4,\n",
    "               window=10,sample=0.001):\n",
    "    \n",
    "    self.num_features=num_features\n",
    "    self.min_count=min_count\n",
    "    self.workers=workers\n",
    "    self.window=window\n",
    "    self.sample=sample\n",
    "    self.wv=pre_trained_model\n",
    "    if pre_trained_model:\n",
    "        self.word_index = set(self.wv.index_to_key)\n",
    "\n",
    "  def fit(self,X):\n",
    "      if not self.wv:\n",
    "        X = X.swifter.apply(nltk.word_tokenize)\n",
    "        model = word2vec.Word2Vec(X, workers = self.workers,\n",
    "                                vector_size = self.num_features, min_count = self.min_count,\n",
    "                                window = self.window, sample = self.sample)\n",
    "        self.wv = model.wv\n",
    "        self.word_index = set(self.wv.index_to_key)\n",
    "\n",
    "  def predict(self,comment):\n",
    "\n",
    "    key_words = filter(lambda w: w in self.word_index, nltk.word_tokenize(comment))\n",
    "    vectors = self.wv[key_words]\n",
    "    return np.divide(np.sum(vectors, axis=0),len(vectors))\n",
    "\n",
    "  def fit_transform(self, X):\n",
    "      if not self.wv:\n",
    "        self.fit(X)\n",
    "      return X.swifter.apply(lambda x: pd.Series(self.predict(x)))\n",
    "\n",
    "  def transform(self, X):\n",
    "      return X.swifter.apply(lambda x: pd.Series(self.predict(x)))"
   ],
   "execution_count": 113,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4hXhrjvwZkA",
    "outputId": "5d6a9200-df85-4f4b-99cb-cf42fdaa9168",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "X_train_w2v, X_test_w2v, Y_train_w2v, Y_test_w2v = vectorize_data(X, Y, Word2VecAdapter(num_features=500))"
   ],
   "execution_count": 114,
   "outputs": [
    {
     "data": {
      "text/plain": "Pandas Apply:   0%|          | 0/3000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "efed12ef31d14d6b84353d33f830b4b3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Pandas Apply:   0%|          | 0/3000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "411a7153ac8e4ea6865686b01bd1f40b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Pandas Apply:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e503aa47f2e24530b85e12791cc60bdb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "Best Score: 0.7600499499526963\n",
      "Best Params: {'C': 700, 'class_weight': 'balanced', 'max_iter': 1000, 'n_jobs': -1, 'penalty': 'l2', 'solver': 'saga'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mryf/PycharmProjects/ml_final_project/venv/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "w2v_log = LogisticRegression()\n",
    "w2v_log = GridSearchCV(estimator=w2v_log, param_grid=logistic_grid, **general_grid_params)\n",
    "w2v_log.fit(X_train_w2v, Y_train_w2v)\n",
    "print(f'Best Score: {w2v_log.best_score_}')\n",
    "print(f'Best Params: {w2v_log.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.79      0.76      0.77       486\n",
      "    negative       0.78      0.80      0.79       514\n",
      "\n",
      "    accuracy                           0.78      1000\n",
      "   macro avg       0.78      0.78      0.78      1000\n",
      "weighted avg       0.78      0.78      0.78      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[369 117]\n",
      " [101 413]]\n",
      "Accuracy:\n",
      " 0.782\n"
     ]
    }
   ],
   "source": [
    "analysis(Y_test_w2v, w2v_log.predict(X_test_w2v))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "Best Score: 0.784313544370445\n",
      "Best Params: {'C': 700, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "w2v_svm = svm.SVC()\n",
    "w2v_svm = GridSearchCV(estimator=w2v_svm, param_grid=svc_grid, **general_grid_params)\n",
    "w2v_svm.fit(X_train_w2v, Y_train_w2v)\n",
    "print(f'Best Score: {w2v_svm.best_score_}')\n",
    "print(f'Best Params: {w2v_svm.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.81      0.76      0.78       486\n",
      "    negative       0.79      0.83      0.81       514\n",
      "\n",
      "    accuracy                           0.80      1000\n",
      "   macro avg       0.80      0.80      0.80      1000\n",
      "weighted avg       0.80      0.80      0.80      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[370 116]\n",
      " [ 88 426]]\n",
      "Accuracy:\n",
      " 0.796\n"
     ]
    }
   ],
   "source": [
    "analysis(Y_test_w2v, w2v_svm.predict(X_test_w2v))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n",
      "Best Score: 0.784313544370445\n",
      "Best Params: {'C': 700, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "w2v_knn = KNeighborsClassifier()\n",
    "w2v_knn = GridSearchCV(estimator=w2v_knn, param_grid=knn_grid, **general_grid_params)\n",
    "w2v_knn.fit(X_train_w2v, Y_train_w2v)\n",
    "print(f'Best Score: {w2v_svm.best_score_}')\n",
    "print(f'Best Params: {w2v_svm.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.81      0.76      0.78       486\n",
      "    negative       0.79      0.83      0.81       514\n",
      "\n",
      "    accuracy                           0.80      1000\n",
      "   macro avg       0.80      0.80      0.80      1000\n",
      "weighted avg       0.80      0.80      0.80      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[370 116]\n",
      " [ 88 426]]\n",
      "Accuracy:\n",
      " 0.796\n"
     ]
    }
   ],
   "source": [
    "analysis(Y_test_w2v, w2v_svm.predict(X_test_w2v))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparison"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For classifier LR, best BoW score is 0.8128492870528445, whereas best W2V score is 0.7600499499526963\n",
      "So BoW is better with parameters {'C': 1, 'class_weight': 'balanced', 'max_iter': 1000, 'n_jobs': -1, 'penalty': 'l2', 'solver': 'saga'}\n",
      "For classifier SVM, best BoW score is 0.8137394686192903, whereas best W2V score is 0.784313544370445\n",
      "So BoW is better with parameters {'C': 1, 'kernel': 'rbf'}\n",
      "For classifier KNN, best BoW score is 0.67243206392765, whereas best W2V score is 0.6576011157601116\n",
      "So BoW is better with parameters {'n_jobs': -1, 'n_neighbors': 21}\n"
     ]
    }
   ],
   "source": [
    "summary = {\n",
    "    'LR': {'BoW': bow_log, 'W2V': w2v_log},\n",
    "    'SVM' : {'BoW': bow_svm, 'W2V': w2v_svm},\n",
    "    'KNN': {'BoW': bow_knn, 'W2V': w2v_knn},\n",
    "  }\n",
    "\n",
    "for name, values in summary.items():\n",
    "    print(f'For classifier {name}, best BoW score is {values[\"BoW\"].best_score_}, whereas best W2V score is {values[\"W2V\"].best_score_}')\n",
    "    best_model = \"BoW\" if values[\"BoW\"].best_score_ > values[\"W2V\"].best_score_ else \"W2V\"\n",
    "    print(f'So {best_model} is better with parameters {values[best_model].best_params_}')\n",
    "    filename = name + '.pkl'\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(values[best_model], f)\n",
    "\n",
    "del summary, bow_log, w2v_log, bow_svm, w2v_svm, bow_knn, w2v_knn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MLP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "mlp_grid = {\n",
    "    'hidden_layer_sizes':[(500, 250), (1000, 250), (500, 250, 250), (1000, 500,250)],\n",
    "    'activation':['tanh', 'relu'],\n",
    "    'solver':['sgd'],\n",
    "    'alpha':[1],\n",
    "    'learning_rate':['adaptive'],\n",
    "    'max_iter':[1000]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## W2V"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mryf/PycharmProjects/ml_final_project/venv/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "MLPClassifier(activation='tanh', alpha=1, hidden_layer_sizes=(500, 250),\n              learning_rate='adaptive', max_iter=1000, solver='sgd')"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_w2v = MLPClassifier()\n",
    "mlp_w2v = GridSearchCV(estimator=mlp_w2v, param_grid=mlp_grid, **general_grid_params)\n",
    "mlp_w2v.fit(X_train_w2v, Y_train_w2v)\n",
    "print(f'Best Score: {mlp_w2v.best_score_}')\n",
    "print(f'Best Params: {mlp_w2v.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: Classification\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.68      0.69      0.69       486\n",
      "    negative       0.70      0.70      0.70       514\n",
      "\n",
      "    accuracy                           0.69      1000\n",
      "   macro avg       0.69      0.69      0.69      1000\n",
      "weighted avg       0.69      0.69      0.69      1000\n",
      "\n",
      "Matrix: Confusion\n",
      " [[335 151]\n",
      " [156 358]]\n",
      "Accuracy:\n",
      " 0.693\n"
     ]
    }
   ],
   "source": [
    "analysis(Y_test_w2v, mlp_w2v.predict(X_test_w2v))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del X_train_w2v, X_test_w2v, Y_train_w2v, Y_test_w2v"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BoW"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mlp_bow = MLPClassifier()\n",
    "mlp_bow = GridSearchCV(estimator=mlp_bow, param_grid=mlp_grid, **general_grid_params)\n",
    "mlp_bow.fit(X_train_bow, Y_train_bow)\n",
    "print(f'Best Score: {mlp_bow.best_score_}')\n",
    "print(f'Best Params: {mlp_bow.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "analysis(Y_test_bow, mlp_bow.predict(X_test_bow))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del X_train_bow, X_test_bow, Y_train_bow, Y_test_bow"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TD-IDF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mlp_idf = MLPClassifier()\n",
    "mlp_idf = GridSearchCV(estimator=mlp_idf, param_grid=mlp_grid, **general_grid_params)\n",
    "X_train_idf, X_test_idf, Y_train_idf, Y_test_idf = vectorize_data(X, Y, TfidfVectorizer(max_features=2000))\n",
    "mlp_idf.fit(X_train_idf, Y_train_idf)\n",
    "print(f'Best Score: {mlp_idf.best_score_}')\n",
    "print(f'Best Params: {mlp_idf.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "analysis(Y_train_idf, mlp_bow.predict(X_test_idf))\n",
    "del X_train_idf, X_test_idf, Y_train_idf, Y_test_idf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparison"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Best scores:')\n",
    "print(f'W2V: {mlp_w2v.best_score_} with params: {mlp_w2v.best_params_}')\n",
    "print(f'BoW: {mlp_bow.best_score_} with params: {mlp_bow.best_params_}')\n",
    "print(f'MLP: {mlp_idf.best_score_} with params: {mlp_idf.best_params_}')\n",
    "best_mlp = max(mlp_w2v, mlp_bow, mlp_idf, lambda mlp: mlp.best_score_)\n",
    "with open('best.pkl', 'wb') as f:\n",
    "    pickle.dump(best_mlp, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}